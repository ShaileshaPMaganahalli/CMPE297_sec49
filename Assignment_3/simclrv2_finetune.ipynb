{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simclrv2_finetune.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/29RKqoSjukQF0q34w969",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyus3003/CMPE297_sec49/blob/master/Assignment_3/simclrv2_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZzZZA_VvSBQ"
      },
      "source": [
        "# Simclrv2 fine tuning.\n",
        "\n",
        "The colab below shows the demonstration of simclrv2 pretrained model loading and fine tuning. \n",
        "The flower dataset is used to check the results of fine tuning where it gives an accuracy of 89%.\n",
        "Below a normal resent50 pretrained model is used to check the result of flower data classification, where we could get an accuracy of 74% with normal resnet50 pretrained model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jrMTulRFo_t"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1GfO1RqbUNJ"
      },
      "source": [
        "import collections\n",
        "import io\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from six.moves import urllib\n",
        "\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as sk_metrics\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQr7H1THv_US"
      },
      "source": [
        "Some of the code sections are taken from google research github, which is used for augmnatation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni-WikBQGEJA"
      },
      "source": [
        "EETA_DEFAULT = 0.001\n",
        "\n",
        "class LARSOptimizer(tf.train.Optimizer):\n",
        "\n",
        "  def __init__(self,\n",
        "               learning_rate,\n",
        "               momentum=0.9,\n",
        "               use_nesterov=False,\n",
        "               weight_decay=0.0,\n",
        "               exclude_from_weight_decay=None,\n",
        "               exclude_from_layer_adaptation=None,\n",
        "               classic_momentum=True,\n",
        "               eeta=EETA_DEFAULT,\n",
        "               name=\"LARSOptimizer\"):\n",
        "   \n",
        "    super(LARSOptimizer, self).__init__(False, name)\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.momentum = momentum\n",
        "    self.weight_decay = weight_decay\n",
        "    self.use_nesterov = use_nesterov\n",
        "    self.classic_momentum = classic_momentum\n",
        "    self.eeta = eeta\n",
        "    self.exclude_from_weight_decay = exclude_from_weight_decay\n",
        "    \n",
        "    if exclude_from_layer_adaptation:\n",
        "      self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
        "    else:\n",
        "      self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
        "\n",
        "  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n",
        "    if global_step is None:\n",
        "      global_step = tf.train.get_or_create_global_step()\n",
        "    new_global_step = global_step + 1\n",
        "\n",
        "    assignments = []\n",
        "    for (grad, param) in grads_and_vars:\n",
        "      if grad is None or param is None:\n",
        "        continue\n",
        "\n",
        "      param_name = param.op.name\n",
        "\n",
        "      v = tf.get_variable(\n",
        "          name=param_name + \"/Momentum\",\n",
        "          shape=param.shape.as_list(),\n",
        "          dtype=tf.float32,\n",
        "          trainable=False,\n",
        "          initializer=tf.zeros_initializer())\n",
        "\n",
        "      if self._use_weight_decay(param_name):\n",
        "        grad += self.weight_decay * param\n",
        "\n",
        "      if self.classic_momentum:\n",
        "        trust_ratio = 1.0\n",
        "        if self._do_layer_adaptation(param_name):\n",
        "          w_norm = tf.norm(param, ord=2)\n",
        "          g_norm = tf.norm(grad, ord=2)\n",
        "          trust_ratio = tf.where(\n",
        "              tf.greater(w_norm, 0), tf.where(\n",
        "                  tf.greater(g_norm, 0), (self.eeta * w_norm / g_norm),\n",
        "                  1.0),\n",
        "              1.0)\n",
        "        scaled_lr = self.learning_rate * trust_ratio\n",
        "\n",
        "        next_v = tf.multiply(self.momentum, v) + scaled_lr * grad\n",
        "        if self.use_nesterov:\n",
        "          update = tf.multiply(self.momentum, next_v) + scaled_lr * grad\n",
        "        else:\n",
        "          update = next_v\n",
        "        next_param = param - update\n",
        "      else:\n",
        "        next_v = tf.multiply(self.momentum, v) + grad\n",
        "        if self.use_nesterov:\n",
        "          update = tf.multiply(self.momentum, next_v) + grad\n",
        "        else:\n",
        "          update = next_v\n",
        "\n",
        "        trust_ratio = 1.0\n",
        "        if self._do_layer_adaptation(param_name):\n",
        "          w_norm = tf.norm(param, ord=2)\n",
        "          v_norm = tf.norm(update, ord=2)\n",
        "          trust_ratio = tf.where(\n",
        "              tf.greater(w_norm, 0), tf.where(\n",
        "                  tf.greater(v_norm, 0), (self.eeta * w_norm / v_norm),\n",
        "                  1.0),\n",
        "              1.0)\n",
        "        scaled_lr = trust_ratio * self.learning_rate\n",
        "        next_param = param - scaled_lr * update\n",
        "\n",
        "      assignments.extend(\n",
        "          [param.assign(next_param),\n",
        "           v.assign(next_v),\n",
        "           global_step.assign(new_global_step)])\n",
        "    return tf.group(*assignments, name=name)\n",
        "\n",
        "  def _use_weight_decay(self, param_name):\n",
        "    \n",
        "    if not self.weight_decay:\n",
        "      return False\n",
        "    if self.exclude_from_weight_decay:\n",
        "      for r in self.exclude_from_weight_decay:\n",
        "        if re.search(r, param_name) is not None:\n",
        "          return False\n",
        "    return True\n",
        "\n",
        "  def _do_layer_adaptation(self, param_name):\n",
        "   \n",
        "    if self.exclude_from_layer_adaptation:\n",
        "      for r in self.exclude_from_layer_adaptation:\n",
        "        if re.search(r, param_name) is not None:\n",
        "          return False\n",
        "    return True"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVXe-Oa9HlHa",
        "outputId": "08283ee4-5d9f-4f71-a869-3043fd352d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! cp \"/content/my_utils.py\" ."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: '/content/my_utils.py' and './my_utils.py' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUtYBiVRIfCU",
        "outputId": "988abe21-9ba1-4b81-e282-b6d79d207863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "! python my_utils.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-26 06:39:39.801025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"my_utils.py\", line 5, in <module>\n",
            "    tf.disable_eager_execution()\n",
            "AttributeError: module 'tensorflow' has no attribute 'disable_eager_execution'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlxFS-nzHHFY"
      },
      "source": [
        "from my_utils import *"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDAKcbMTLtzT"
      },
      "source": [
        "# # Code snippet credit: \"https://github.com/google-research/simclr\"\n",
        "\n",
        "FLAGS_color_jitter_strength = 0.3\n",
        "CROP_PROPORTION = 0.875  # Standard for ImageNet.\n",
        "\n",
        "\n",
        "def random_apply(func, p, x):\n",
        "  \"\"\"Randomly apply function func to x with probability p.\"\"\"\n",
        "  return tf.cond(\n",
        "      tf.less(tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "              tf.cast(p, tf.float32)),\n",
        "      lambda: func(x),\n",
        "      lambda: x)\n",
        "\n",
        "\n",
        "def random_brightness(image, max_delta, impl='simclrv2'):\n",
        "  \"\"\"A multiplicative vs additive change of brightness.\"\"\"\n",
        "  if impl == 'simclrv2':\n",
        "    factor = tf.random_uniform(\n",
        "        [], tf.maximum(1.0 - max_delta, 0), 1.0 + max_delta)\n",
        "    image = image * factor\n",
        "  elif impl == 'simclrv1':\n",
        "    image = random_brightness(image, max_delta=max_delta)\n",
        "  else:\n",
        "    raise ValueError('Unknown impl {} for random brightness.'.format(impl))\n",
        "  return image\n",
        "\n",
        "\n",
        "def to_grayscale(image, keep_channels=True):\n",
        "  image = tf.image.rgb_to_grayscale(image)\n",
        "  if keep_channels:\n",
        "    image = tf.tile(image, [1, 1, 3])\n",
        "  return image\n",
        "\n",
        "\n",
        "def color_jitter(image,\n",
        "                 strength,\n",
        "                 random_order=True):\n",
        "  \"\"\"Distorts the color of the image.\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    strength: the floating number for the strength of the color augmentation.\n",
        "    random_order: A bool, specifying whether to randomize the jittering order.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  brightness = 0.8 * strength\n",
        "  contrast = 0.8 * strength\n",
        "  saturation = 0.8 * strength\n",
        "  hue = 0.2 * strength\n",
        "  if random_order:\n",
        "    return color_jitter_rand(image, brightness, contrast, saturation, hue)\n",
        "  else:\n",
        "    return color_jitter_nonrand(image, brightness, contrast, saturation, hue)\n",
        "\n",
        "\n",
        "def color_jitter_nonrand(image, brightness=0, contrast=0, saturation=0, hue=0):\n",
        "  \"\"\"Distorts the color of the image (jittering order is fixed).\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    brightness: A float, specifying the brightness for color jitter.\n",
        "    contrast: A float, specifying the contrast for color jitter.\n",
        "    saturation: A float, specifying the saturation for color jitter.\n",
        "    hue: A float, specifying the hue for color jitter.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('distort_color'):\n",
        "    def apply_transform(i, x, brightness, contrast, saturation, hue):\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\n",
        "      if brightness != 0 and i == 0:\n",
        "        x = random_brightness(x, max_delta=brightness)\n",
        "      elif contrast != 0 and i == 1:\n",
        "        x = tf.image.random_contrast(\n",
        "            x, lower=1-contrast, upper=1+contrast)\n",
        "      elif saturation != 0 and i == 2:\n",
        "        x = tf.image.random_saturation(\n",
        "            x, lower=1-saturation, upper=1+saturation)\n",
        "      elif hue != 0:\n",
        "        x = tf.image.random_hue(x, max_delta=hue)\n",
        "      return x\n",
        "\n",
        "    for i in range(4):\n",
        "      image = apply_transform(i, image, brightness, contrast, saturation, hue)\n",
        "      image = tf.clip_by_value(image, 0., 1.)\n",
        "    return image\n",
        "\n",
        "\n",
        "def color_jitter_rand(image, brightness=0, contrast=0, saturation=0, hue=0):\n",
        "  \"\"\"Distorts the color of the image (jittering order is random).\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    brightness: A float, specifying the brightness for color jitter.\n",
        "    contrast: A float, specifying the contrast for color jitter.\n",
        "    saturation: A float, specifying the saturation for color jitter.\n",
        "    hue: A float, specifying the hue for color jitter.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('distort_color'):\n",
        "    def apply_transform(i, x):\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\n",
        "      def brightness_foo():\n",
        "        if brightness == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return random_brightness(x, max_delta=brightness)\n",
        "      def contrast_foo():\n",
        "        if contrast == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_contrast(x, lower=1-contrast, upper=1+contrast)\n",
        "      def saturation_foo():\n",
        "        if saturation == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_saturation(\n",
        "              x, lower=1-saturation, upper=1+saturation)\n",
        "      def hue_foo():\n",
        "        if hue == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_hue(x, max_delta=hue)\n",
        "      x = tf.cond(tf.less(i, 2),\n",
        "                  lambda: tf.cond(tf.less(i, 1), brightness_foo, contrast_foo),\n",
        "                  lambda: tf.cond(tf.less(i, 3), saturation_foo, hue_foo))\n",
        "      return x\n",
        "\n",
        "    perm = tf.random_shuffle(tf.range(4))\n",
        "    for i in range(4):\n",
        "      image = apply_transform(perm[i], image)\n",
        "      image = tf.clip_by_value(image, 0., 1.)\n",
        "    return image\n",
        "\n",
        "\n",
        "def _compute_crop_shape(\n",
        "    image_height, image_width, aspect_ratio, crop_proportion):\n",
        "  \"\"\"Compute aspect ratio-preserving shape for central crop.\n",
        "  The resulting shape retains `crop_proportion` along one side and a proportion\n",
        "  less than or equal to `crop_proportion` along the other side.\n",
        "  Args:\n",
        "    image_height: Height of image to be cropped.\n",
        "    image_width: Width of image to be cropped.\n",
        "    aspect_ratio: Desired aspect ratio (width / height) of output.\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\n",
        "  Returns:\n",
        "    crop_height: Height of image after cropping.\n",
        "    crop_width: Width of image after cropping.\n",
        "  \"\"\"\n",
        "  image_width_float = tf.cast(image_width, tf.float32)\n",
        "  image_height_float = tf.cast(image_height, tf.float32)\n",
        "\n",
        "  def _requested_aspect_ratio_wider_than_image():\n",
        "    crop_height = tf.cast(tf.rint(\n",
        "        crop_proportion / aspect_ratio * image_width_float), tf.int32)\n",
        "    crop_width = tf.cast(tf.rint(\n",
        "        crop_proportion * image_width_float), tf.int32)\n",
        "    return crop_height, crop_width\n",
        "\n",
        "  def _image_wider_than_requested_aspect_ratio():\n",
        "    crop_height = tf.cast(\n",
        "        tf.rint(crop_proportion * image_height_float), tf.int32)\n",
        "    crop_width = tf.cast(tf.rint(\n",
        "        crop_proportion * aspect_ratio *\n",
        "        image_height_float), tf.int32)\n",
        "    return crop_height, crop_width\n",
        "\n",
        "  return tf.cond(\n",
        "      aspect_ratio > image_width_float / image_height_float,\n",
        "      _requested_aspect_ratio_wider_than_image,\n",
        "      _image_wider_than_requested_aspect_ratio)\n",
        "\n",
        "\n",
        "def center_crop(image, height, width, crop_proportion):\n",
        "  \"\"\"Crops to center of image and rescales to desired size.\n",
        "  Args:\n",
        "    image: Image Tensor to crop.\n",
        "    height: Height of image to be cropped.\n",
        "    width: Width of image to be cropped.\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\n",
        "  Returns:\n",
        "    A `height` x `width` x channels Tensor holding a central crop of `image`.\n",
        "  \"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  image_height = shape[0]\n",
        "  image_width = shape[1]\n",
        "  crop_height, crop_width = _compute_crop_shape(\n",
        "      image_height, image_width, height / width, crop_proportion)\n",
        "  offset_height = ((image_height - crop_height) + 1) // 2\n",
        "  offset_width = ((image_width - crop_width) + 1) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_height, offset_width, crop_height, crop_width)\n",
        "\n",
        "  image = tf.image.resize_bicubic([image], [height, width])[0]\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def distorted_bounding_box_crop(image,\n",
        "                                bbox,\n",
        "                                min_object_covered=0.1,\n",
        "                                aspect_ratio_range=(0.75, 1.33),\n",
        "                                area_range=(0.05, 1.0),\n",
        "                                max_attempts=100,\n",
        "                                scope=None):\n",
        "  \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n",
        "  See `tf.image.sample_distorted_bounding_box` for more documentation.\n",
        "  Args:\n",
        "    image: `Tensor` of image data.\n",
        "    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\n",
        "        where each coordinate is [0, 1) and the coordinates are arranged\n",
        "        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\n",
        "        image.\n",
        "    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n",
        "        area of the image must contain at least this fraction of any bounding\n",
        "        box supplied.\n",
        "    aspect_ratio_range: An optional list of `float`s. The cropped area of the\n",
        "        image must have an aspect ratio = width / height within this range.\n",
        "    area_range: An optional list of `float`s. The cropped area of the image\n",
        "        must contain a fraction of the supplied image within in this range.\n",
        "    max_attempts: An optional `int`. Number of attempts at generating a cropped\n",
        "        region of the image of the specified constraints. After `max_attempts`\n",
        "        failures, return the entire image.\n",
        "    scope: Optional `str` for name scope.\n",
        "  Returns:\n",
        "    (cropped image `Tensor`, distorted bbox `Tensor`).\n",
        "  \"\"\"\n",
        "  with tf.name_scope(scope, 'distorted_bounding_box_crop', [image, bbox]):\n",
        "    shape = tf.shape(image)\n",
        "    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n",
        "        shape,\n",
        "        bounding_boxes=bbox,\n",
        "        min_object_covered=min_object_covered,\n",
        "        aspect_ratio_range=aspect_ratio_range,\n",
        "        area_range=area_range,\n",
        "        max_attempts=max_attempts,\n",
        "        use_image_if_no_bounding_boxes=True)\n",
        "    bbox_begin, bbox_size, _ = sample_distorted_bounding_box\n",
        "\n",
        "    # Crop the image to the specified bounding box.\n",
        "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\n",
        "    target_height, target_width, _ = tf.unstack(bbox_size)\n",
        "    image = tf.image.crop_to_bounding_box(\n",
        "        image, offset_y, offset_x, target_height, target_width)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def crop_and_resize(image, height, width):\n",
        "  \"\"\"Make a random crop and resize it to height `height` and width `width`.\n",
        "  Args:\n",
        "    image: Tensor representing the image.\n",
        "    height: Desired image height.\n",
        "    width: Desired image width.\n",
        "  Returns:\n",
        "    A `height` x `width` x channels Tensor holding a random crop of `image`.\n",
        "  \"\"\"\n",
        "  bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n",
        "  aspect_ratio = width / height\n",
        "  image = distorted_bounding_box_crop(\n",
        "      image,\n",
        "      bbox,\n",
        "      min_object_covered=0.1,\n",
        "      aspect_ratio_range=(3. / 4 * aspect_ratio, 4. / 3. * aspect_ratio),\n",
        "      area_range=(0.08, 1.0),\n",
        "      max_attempts=100,\n",
        "      scope=None)\n",
        "  return tf.image.resize_bicubic([image], [height, width])[0]\n",
        "\n",
        "\n",
        "def gaussian_blur(image, kernel_size, sigma, padding='SAME'):\n",
        "  \"\"\"Blurs the given image with separable convolution.\n",
        "  Args:\n",
        "    image: Tensor of shape [height, width, channels] and dtype float to blur.\n",
        "    kernel_size: Integer Tensor for the size of the blur kernel. This is should\n",
        "      be an odd number. If it is an even number, the actual kernel size will be\n",
        "      size + 1.\n",
        "    sigma: Sigma value for gaussian operator.\n",
        "    padding: Padding to use for the convolution. Typically 'SAME' or 'VALID'.\n",
        "  Returns:\n",
        "    A Tensor representing the blurred image.\n",
        "  \"\"\"\n",
        "  radius = tf.to_int32(kernel_size / 2)\n",
        "  kernel_size = radius * 2 + 1\n",
        "  x = tf.to_float(tf.range(-radius, radius + 1))\n",
        "  blur_filter = tf.exp(\n",
        "      -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.to_float(sigma), 2.0)))\n",
        "  blur_filter /= tf.reduce_sum(blur_filter)\n",
        "  # One vertical and one horizontal filter.\n",
        "  blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "  blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "  num_channels = tf.shape(image)[-1]\n",
        "  blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
        "  blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
        "  expand_batch_dim = image.shape.ndims == 3\n",
        "  if expand_batch_dim:\n",
        "    # Tensorflow requires batched input to convolutions, which we can fake with\n",
        "    # an extra dimension.\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "  blurred = tf.nn.depthwise_conv2d(\n",
        "      image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
        "  blurred = tf.nn.depthwise_conv2d(\n",
        "      blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
        "  if expand_batch_dim:\n",
        "    blurred = tf.squeeze(blurred, axis=0)\n",
        "  return blurred\n",
        "\n",
        "\n",
        "def random_crop_with_resize(image, height, width, p=1.0):\n",
        "  \"\"\"Randomly crop and resize an image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    p: Probability of applying this transformation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  def _transform(image):  # pylint: disable=missing-docstring\n",
        "    image = crop_and_resize(image, height, width)\n",
        "    return image\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def random_color_jitter(image, p=1.0):\n",
        "  def _transform(image):\n",
        "    color_jitter_t = functools.partial(\n",
        "        color_jitter, strength=FLAGS_color_jitter_strength)\n",
        "    image = random_apply(color_jitter_t, p=0.8, x=image)\n",
        "    return random_apply(to_grayscale, p=0.2, x=image)\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def random_blur(image, height, width, p=1.0):\n",
        "  \"\"\"Randomly blur an image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    p: probability of applying this transformation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  del width\n",
        "  def _transform(image):\n",
        "    sigma = tf.random.uniform([], 0.1, 2.0, dtype=tf.float32)\n",
        "    return gaussian_blur(\n",
        "        image, kernel_size=height//10, sigma=sigma, padding='SAME')\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def batch_random_blur(images_list, height, width, blur_probability=0.5):\n",
        "  \"\"\"Apply efficient batch data transformations.\n",
        "  Args:\n",
        "    images_list: a list of image tensors.\n",
        "    height: the height of image.\n",
        "    width: the width of image.\n",
        "    blur_probability: the probaility to apply the blur operator.\n",
        "  Returns:\n",
        "    Preprocessed feature list.\n",
        "  \"\"\"\n",
        "  def generate_selector(p, bsz):\n",
        "    shape = [bsz, 1, 1, 1]\n",
        "    selector = tf.cast(\n",
        "        tf.less(tf.random_uniform(shape, 0, 1, dtype=tf.float32), p),\n",
        "        tf.float32)\n",
        "    return selector\n",
        "\n",
        "  new_images_list = []\n",
        "  for images in images_list:\n",
        "    images_new = random_blur(images, height, width, p=1.)\n",
        "    selector = generate_selector(blur_probability, tf.shape(images)[0])\n",
        "    images = images_new * selector + images * (1 - selector)\n",
        "    images = tf.clip_by_value(images, 0., 1.)\n",
        "    new_images_list.append(images)\n",
        "\n",
        "  return new_images_list\n",
        "\n",
        "\n",
        "def preprocess_for_train(image, height, width,\n",
        "                         color_distort=True, crop=True, flip=True):\n",
        "  \"\"\"Preprocesses the given image for training.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    color_distort: Whether to apply the color distortion.\n",
        "    crop: Whether to crop the image.\n",
        "    flip: Whether or not to flip left and right of an image.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  if crop:\n",
        "    image = random_crop_with_resize(image, height, width)\n",
        "  if flip:\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "  if color_distort:\n",
        "    image = random_color_jitter(image)\n",
        "  image = tf.reshape(image, [height, width, 3])\n",
        "  image = tf.clip_by_value(image, 0., 1.)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_for_eval(image, height, width, crop=True):\n",
        "  \"\"\"Preprocesses the given image for evaluation.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    crop: Whether or not to (center) crop the test images.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  if crop:\n",
        "    image = center_crop(image, height, width, crop_proportion=CROP_PROPORTION)\n",
        "  image = tf.reshape(image, [height, width, 3])\n",
        "  image = tf.clip_by_value(image, 0., 1.)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_image(image, height, width, is_training=False,\n",
        "                     color_distort=True, test_crop=True):\n",
        "  \"\"\"Preprocesses the given image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    is_training: `bool` for whether the preprocessing is for training.\n",
        "    color_distort: whether to apply the color distortion.\n",
        "    test_crop: whether or not to extract a central crop of the images\n",
        "        (as for standard ImageNet evaluation) during the evaluation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor` of range [0, 1].\n",
        "  \"\"\"\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  if is_training:\n",
        "    return preprocess_for_train(image, height, width, color_distort)\n",
        "  else:\n",
        "    return preprocess_for_eval(image, height, width, test_crop)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV0iIT7DGMie"
      },
      "source": [
        "\n",
        "\n",
        "batch_size = 64\n",
        "dataset_name = 'tf_flowers'\n",
        "\n",
        "tfds_dataset, tfds_info = tfds.load(\n",
        "    dataset_name, split='train', with_info=True)\n",
        "num_images = tfds_info.splits['train'].num_examples\n",
        "num_classes = tfds_info.features['label'].num_classes\n",
        "\n",
        "def _preprocess(x):\n",
        "  x['image'] = preprocess_image(\n",
        "      x['image'], 224, 224, is_training=False, color_distort=False)\n",
        "  return x\n",
        "x = tfds_dataset.map(_preprocess).batch(batch_size)\n",
        "x = tf.data.make_one_shot_iterator(x).get_next()\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cE3XrbvYwD9",
        "outputId": "05a0ad6f-bc53-4fc2-daec-d6b41165aa0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': <tf.Tensor 'IteratorGetNext_1:0' shape=(None, 224, 224, 3) dtype=float32>,\n",
              " 'label': <tf.Tensor 'IteratorGetNext_1:1' shape=(None,) dtype=int64>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cchFKtx9L5mZ",
        "outputId": "ded4c028-bb2a-408d-f609-af600807904b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "learning_rate = 0.1\n",
        "momentum = 0.9\n",
        "weight_decay = 0.\n",
        "\n",
        "\n",
        "\n",
        "hub_path = 'gs://simclr-checkpoints/simclrv2/finetuned_100pct/r50_1x_sk0/hub/'\n",
        "module = hub.Module(hub_path, trainable=False)\n",
        "key = module(inputs=x['image'], signature=\"default\", as_dict=True)\n",
        "\n",
        "\n",
        "with tf.variable_scope('head_supervised_new', reuse=tf.AUTO_REUSE):\n",
        "  logits_t = tf.layers.dense(inputs=key['final_avg_pool'], units=num_classes)\n",
        "loss_t = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    labels=tf.one_hot(x['label'], num_classes), logits=logits_t))\n",
        "\n",
        "\n",
        "optimizer = LARSOptimizer(\n",
        "    learning_rate,\n",
        "    momentum=momentum,\n",
        "    weight_decay=weight_decay,\n",
        "    exclude_from_weight_decay=['batch_normalization', 'bias', 'head_supervised'])\n",
        "variables_to_train = tf.trainable_variables() \n",
        "train_op = optimizer.minimize(\n",
        "    loss_t, global_step=tf.train.get_or_create_global_step(),\n",
        "    var_list=variables_to_train)\n",
        "\n",
        "print('Variables to train:', variables_to_train)\n",
        "key "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-4bd770ffd16c>:12: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-4bd770ffd16c>:12: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Variables to train: [<tf.Variable 'head_supervised_new/dense/kernel:0' shape=(2048, 5) dtype=float32>, <tf.Variable 'head_supervised_new/dense/bias:0' shape=(5,) dtype=float32>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'block_group1': <tf.Tensor 'module_apply_default/base_model/block_group1:0' shape=(None, 56, 56, 256) dtype=float32>,\n",
              " 'block_group2': <tf.Tensor 'module_apply_default/base_model/block_group2:0' shape=(None, 28, 28, 512) dtype=float32>,\n",
              " 'block_group3': <tf.Tensor 'module_apply_default/base_model/block_group3:0' shape=(None, 14, 14, 1024) dtype=float32>,\n",
              " 'block_group4': <tf.Tensor 'module_apply_default/base_model/block_group4:0' shape=(None, 7, 7, 2048) dtype=float32>,\n",
              " 'default': <tf.Tensor 'module_apply_default/base_model/final_avg_pool:0' shape=(None, 2048) dtype=float32>,\n",
              " 'final_avg_pool': <tf.Tensor 'module_apply_default/base_model/final_avg_pool:0' shape=(None, 2048) dtype=float32>,\n",
              " 'initial_conv': <tf.Tensor 'module_apply_default/base_model/initial_conv:0' shape=(None, 112, 112, 64) dtype=float32>,\n",
              " 'initial_max_pool': <tf.Tensor 'module_apply_default/base_model/initial_max_pool:0' shape=(None, 56, 56, 64) dtype=float32>,\n",
              " 'logits_sup': <tf.Tensor 'module_apply_default/head_supervised/linear_layer/linear_layer_out:0' shape=(None, 1000) dtype=float32>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JYvhrH5L-AT"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiiN-vQPMB0l",
        "outputId": "62ec61cd-7a9e-4932-e93d-214482cb4293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "total_iterations = 10\n",
        "\n",
        "for it in range(total_iterations):\n",
        "  _, loss, image, logits, labels = sess.run((train_op, loss_t, x['image'], logits_t, x['label']))\n",
        "  pred = logits.argmax(-1)\n",
        "  correct = np.sum(pred == labels)\n",
        "  total = labels.size\n",
        "  print(\"[Iter {}] Loss: {} Top 1: {}\".format(it+1, loss, correct/float(total)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Iter 1] Loss: 2.096773147583008 Top 1: 0.109375\n",
            "[Iter 2] Loss: 1.8777498006820679 Top 1: 0.421875\n",
            "[Iter 3] Loss: 1.3369698524475098 Top 1: 0.53125\n",
            "[Iter 4] Loss: 0.6426237225532532 Top 1: 0.78125\n",
            "[Iter 5] Loss: 1.5421879291534424 Top 1: 0.640625\n",
            "[Iter 6] Loss: 0.6163402795791626 Top 1: 0.734375\n",
            "[Iter 7] Loss: 0.8286991119384766 Top 1: 0.8125\n",
            "[Iter 8] Loss: 0.5815252065658569 Top 1: 0.8125\n",
            "[Iter 9] Loss: 0.568376898765564 Top 1: 0.859375\n",
            "[Iter 10] Loss: 0.4423409104347229 Top 1: 0.890625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ogL_uDVYi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgwXRgWKr_40"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXLDCdO4wLOV"
      },
      "source": [
        "# Resnet50 pretrained model.\n",
        "\n",
        "A resnet50 pretrained model is used to classify the flower dataset to compare the results of simclrv2. \n",
        "The results shows that simclrv2 gives almost 15% more accuracy than resnet50 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SftIf28fbGJq"
      },
      "source": [
        "\n",
        "\n",
        "FLOWERS_DIR = './flower_photos'\n",
        "TRAIN_FRACTION = 0.8\n",
        "RANDOM_SEED = 2018\n",
        "\n",
        "\n",
        "def download_images():\n",
        "  \"\"\"If the images aren't already downloaded, save them to FLOWERS_DIR.\"\"\"\n",
        "  if not os.path.exists(FLOWERS_DIR):\n",
        "    DOWNLOAD_URL = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "    print('Downloading flower images from %s...' % DOWNLOAD_URL)\n",
        "    urllib.request.urlretrieve(DOWNLOAD_URL, 'flower_photos.tgz')\n",
        "    !tar xfz flower_photos.tgz\n",
        "  print('Flower photos are located in %s' % FLOWERS_DIR)\n",
        "\n",
        "\n",
        "def make_train_and_test_sets():\n",
        "  \"\"\"Split the data into train and test sets and get the label classes.\"\"\"\n",
        "  train_examples, test_examples = [], []\n",
        "  shuffler = random.Random(RANDOM_SEED)\n",
        "  is_root = True\n",
        "  for (dirname, subdirs, filenames) in tf.gfile.Walk(FLOWERS_DIR):\n",
        " \n",
        "    if is_root:\n",
        "      subdirs = sorted(subdirs)\n",
        "      classes = collections.OrderedDict(enumerate(subdirs))\n",
        "      label_to_class = dict([(x, i) for i, x in enumerate(subdirs)])\n",
        "      is_root = False\n",
        "    \n",
        "    else:\n",
        "      filenames.sort()\n",
        "      shuffler.shuffle(filenames)\n",
        "      full_filenames = [os.path.join(dirname, f) for f in filenames]\n",
        "      label = dirname.split('/')[-1]\n",
        "      label_class = label_to_class[label]\n",
        "     \n",
        "      examples = list(zip(full_filenames, [label_class] * len(filenames)))\n",
        "      num_train = int(len(filenames) * TRAIN_FRACTION)\n",
        "      train_examples.extend(examples[:num_train])\n",
        "      test_examples.extend(examples[num_train:])\n",
        "\n",
        "  shuffler.shuffle(train_examples)\n",
        "  shuffler.shuffle(test_examples)\n",
        "  return train_examples, test_examples, classes"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7JVzjY9bImR",
        "outputId": "8637f7d5-fdc7-4564-9406-5b0c356de364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "download_images()\n",
        "TRAIN_EXAMPLES, TEST_EXAMPLES, CLASSES = make_train_and_test_sets()\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "print('\\nThe dataset has %d label classes: %s' % (NUM_CLASSES, CLASSES.values()))\n",
        "print('There are %d training images' % len(TRAIN_EXAMPLES))\n",
        "print('there are %d test images' % len(TEST_EXAMPLES))\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flower photos are located in ./flower_photos\n",
            "\n",
            "The dataset has 5 label classes: odict_values(['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'])\n",
            "There are 2934 training images\n",
            "there are 736 test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JqLf67FbIjt",
        "outputId": "76064b37-b27b-4be3-ca16-7a91c8b4038c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LEARNING_RATE = 0.01\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "# hub_path = 'gs://simclr-checkpoints/simclrv1/finetune_100pct/4x/hub'\n",
        "# https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv1/finetune_100pct/4x/hub\n",
        "image_module = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\")\n",
        "# image_module = hub.Module(hub_path, trainable=False)\n",
        "# image_module = hub.Module('https://tfhub.dev/google/imagenet/mobilenet_v2_035_128/feature_vector/2')\n",
        "\n",
        "# Preprocessing images into tensors with size expected by the image module.\n",
        "encoded_images = tf.placeholder(tf.string, shape=[None])\n",
        "# image_size = hub.get_expected_image_size(image_module)\n",
        "image_size = (128, 128)\n",
        "print(image_size)\n",
        "\n",
        "def decode_and_resize_image(encoded):\n",
        "  decoded = tf.image.decode_jpeg(encoded, channels=3)\n",
        "  decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
        "  return tf.image.resize_images(decoded, image_size)\n",
        "\n",
        "\n",
        "batch_images = tf.map_fn(decode_and_resize_image, encoded_images, dtype=tf.float32)\n",
        "\n",
        "\n",
        "features = image_module(batch_images)\n",
        "\n",
        "\n",
        "def create_model(features):\n",
        "  \"\"\"Build a model for classification from extracted features.\"\"\"\n",
        "  \n",
        "  layer = tf.layers.dense(inputs=features, units=NUM_CLASSES, activation=None)\n",
        "  return layer\n",
        "\n",
        "\n",
        "\n",
        "logits = create_model(features)\n",
        "labels = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
        "\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
        "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
        "train_op = optimizer.minimize(loss=cross_entropy_mean)\n",
        "\n",
        "\n",
        "probabilities = tf.nn.softmax(logits)\n",
        "\n",
        "\n",
        "prediction = tf.argmax(probabilities, 1)\n",
        "correct_prediction = tf.equal(prediction, tf.argmax(labels, 1))\n",
        "\n",
        " \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJOX_ebegEZS"
      },
      "source": [
        "def get_label(example):\n",
        " \n",
        "  return example[1]\n",
        "\n",
        "def get_class(example):\n",
        "\n",
        "  return CLASSES[get_label(example)]\n",
        "\n",
        "def get_encoded_image(example):\n",
        " \n",
        "  image_path = example[0]\n",
        "  return tf.gfile.GFile(image_path, 'rb').read()\n",
        "\n",
        "def get_image(example):\n",
        "  \n",
        "  return plt.imread(io.BytesIO(get_encoded_image(example)), format='jpg')"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_XxLbShbGEz",
        "outputId": "e99ddc8f-65b3-430e-a679-9ba77df2dfd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "NUM_TRAIN_STEPS = 100 \n",
        "\n",
        "TRAIN_BATCH_SIZE = 10 \n",
        "\n",
        "EVAL_EVERY = 10 \n",
        "\n",
        "def get_batch(batch_size=None, test=False):\n",
        " \n",
        "  examples = TEST_EXAMPLES if test else TRAIN_EXAMPLES\n",
        "  batch_examples = random.sample(examples, batch_size) if batch_size else examples\n",
        "  return batch_examples\n",
        "\n",
        "def get_images_and_labels(batch_examples):\n",
        "  images = [get_encoded_image(e) for e in batch_examples]\n",
        "  one_hot_labels = [get_label_one_hot(e) for e in batch_examples]\n",
        "  return images, one_hot_labels\n",
        "\n",
        "def get_label_one_hot(example):\n",
        "  \n",
        "  one_hot_vector = np.zeros(NUM_CLASSES)\n",
        "  np.put(one_hot_vector, get_label(example), 1)\n",
        "  return one_hot_vector\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(NUM_TRAIN_STEPS):\n",
        "   \n",
        "    train_batch = get_batch(batch_size=TRAIN_BATCH_SIZE)\n",
        "    batch_images, batch_labels = get_images_and_labels(train_batch)\n",
        "  \n",
        "    train_loss, _, train_accuracy = sess.run(\n",
        "        [cross_entropy_mean, train_op, accuracy],\n",
        "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
        "    is_final_step = (i == (NUM_TRAIN_STEPS - 1))\n",
        "    if i % EVAL_EVERY == 0 or is_final_step:\n",
        "     \n",
        "      test_batch = get_batch(batch_size=None, test=True)\n",
        "      batch_images, batch_labels = get_images_and_labels(test_batch)\n",
        "   \n",
        "      test_loss, test_accuracy, test_prediction, correct_predicate = sess.run(\n",
        "        [cross_entropy_mean, accuracy, prediction, correct_prediction],\n",
        "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
        "      print('Test accuracy at step %s: %.2f%%' % (i, (test_accuracy * 100)))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy at step 0: 30.16%\n",
            "Test accuracy at step 10: 59.78%\n",
            "Test accuracy at step 20: 70.11%\n",
            "Test accuracy at step 30: 69.57%\n",
            "Test accuracy at step 40: 71.06%\n",
            "Test accuracy at step 50: 69.84%\n",
            "Test accuracy at step 60: 70.52%\n",
            "Test accuracy at step 70: 76.09%\n",
            "Test accuracy at step 80: 73.10%\n",
            "Test accuracy at step 90: 77.72%\n",
            "Test accuracy at step 99: 74.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyuwvxWrwoW9"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    }
  ]
}